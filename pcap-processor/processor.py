# pcap-processor/processor.py (Final Corrected Version)
import os
import subprocess
import json
import time
from pathlib import Path
from kafka import KafkaConsumer, KafkaProducer
from kafka.errors import NoBrokersAvailable

KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:29092")

# This loop makes the script more resilient to startup timing issues.
print("PCAP Processor service started. Attempting to connect to Kafka...", flush=True)
while True:
    try:
        job_consumer = KafkaConsumer(
            'pcap_jobs',
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',
            group_id='pcap_processor_group', # <-- THE CRITICAL FIX
            api_version=(0, 10, 2)
        )
        print("Successfully connected to Kafka. Waiting for jobs...", flush=True)
        break # Exit loop if connection is successful
    except NoBrokersAvailable:
        print("Kafka not ready, waiting 5 seconds to retry...", flush=True)
        time.sleep(5)

results_producer = KafkaProducer(
    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

for message in job_consumer:
    filename = message.value.get('filename')
    if not filename:
        continue

    pcap_path = f"/pcap_storage/{filename}"
    print(f"Received job. Analyzing file: {pcap_path}", flush=True)

    try:
        # Run Zeek on the PCAP file in a temporary directory
        subprocess.run(
            ["zeek", "-r", pcap_path,"policy/tuning/json-logs.zeek"],
            cwd="/tmp",
            capture_output=True,
            text=True,
            check=True # This will raise an error if Zeek fails
        )
        print("Zeek analysis complete.", flush=True)
    except subprocess.CalledProcessError as e:
        print(f"Zeek failed to process the file '{filename}': {e.stderr}", flush=True)
        continue # Skip to the next message

    # Check if Zeek produced a sip.log and publish results
    sip_log_path = Path("/tmp/sip.log")
    if sip_log_path.exists():
        print("Found sip.log. Publishing results to 'voip_logs' topic...", flush=True)
        with open(sip_log_path) as f:
            for line in f:
                if line.startswith("#"):
                    continue
                try:
                    log_data = json.loads(line)
                    log_data["source"] = f"pcap:{filename}" # Add source context
                    results_producer.send('voip_logs', log_data)
                except json.JSONDecodeError:
                    print(f"Skipping malformed line in sip.log: {line.strip()}", flush=True)
        results_producer.flush()
        print(f"Finished publishing results for {filename}.", flush=True)
        os.remove(sip_log_path) # Clean up for the next run
    else:
        print(f"No sip.log generated by Zeek for {filename}.", flush=True)
